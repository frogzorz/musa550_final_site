{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b2a549-1b0b-405b-a536-36a45434eb9e",
   "metadata": {},
   "source": [
    "---\n",
    "format: \n",
    "  html:\n",
    "    toc: false\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481530d3-4256-4271-b03a-97e86e37ea74",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "First, we will load our data from the following sources:\n",
    "\n",
    "- All motor vehicle accidents in Philadelphia, 2018-2023 ([PennDOT](https://gis.penndot.gov/gishub/crashZip/County/Philadelphia/Philadelphia_20[##].zipâ€))\n",
    "    - Filtered by accidents involving non-motorists\n",
    "- American Community Survey 5-year estimates (USCB ACS via `census`)\n",
    "- Philadelphia road network from [PennDOT Open Data](https://data-pennshare.opendata.arcgis.com/datasets/PennShare::pennsylvania-local-roads/about)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50683b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pysal\n",
    "import esda\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import folium\n",
    "import cenpy as c\n",
    "import osmnx as ox\n",
    "import json\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "from census import Census\n",
    "from us import states\n",
    "from folium import plugins\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from shapely.geometry import Point, LineString\n",
    "from esda.moran import Moran_Local\n",
    "from libpysal.weights import Queen\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303a1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2018...\n",
      "Processing data for year 2019...\n",
      "Processing data for year 2020...\n",
      "Processing data for year 2021...\n",
      "Processing data for year 2022...\n",
      "Processing data for year 2023...\n",
      "Combined all years into a single DataFrame.\n",
      "Deleted: philly_crash_data/Philadelphia_2018.zip\n",
      "Deleted: philly_crash_data/CRASH_PHILADELPHIA_2018.csv\n",
      "Deleted: philly_crash_data/Philadelphia_2019.zip\n",
      "Deleted: philly_crash_data/CRASH_PHILADELPHIA_2019.csv\n",
      "Deleted: philly_crash_data/Philadelphia_2020.zip\n",
      "Deleted: philly_crash_data/CRASH_PHILADELPHIA_2020.csv\n",
      "Deleted: philly_crash_data/Philadelphia_2021.zip\n",
      "Deleted: philly_crash_data/CRASH_PHILADELPHIA_2021.csv\n",
      "Deleted: philly_crash_data/Philadelphia_2022.zip\n",
      "Deleted: philly_crash_data/CRASH_PHILADELPHIA_2022.csv\n",
      "Deleted: philly_crash_data/Philadelphia_2023.zip\n",
      "Deleted: philly_crash_data/CRASH_PHILADELPHIA_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xd/w__5x95d37b_lkks4djd2m9h0000gp/T/ipykernel_13343/1287730822.py:40: DtypeWarning: Columns (91,92,95,96,97) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_filename)\n"
     ]
    }
   ],
   "source": [
    "# define download paths\n",
    "base_url = \"https://gis.penndot.gov/gishub/crashZip/County/Philadelphia/Philadelphia_\"\n",
    "download_dir = \"philly_crash_data\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# create an empty list to store dataframes\n",
    "crash_data_list = []\n",
    "\n",
    "# loop through 2018 to 2023\n",
    "for year in range(2018, 2024):\n",
    "    print(f\"Processing data for year {year}...\")\n",
    "    zip_filename = f\"{download_dir}/Philadelphia_{year}.zip\"\n",
    "    csv_filename = f\"{download_dir}/CRASH_PHILADELPHIA_{year}.csv\"\n",
    "\n",
    "    # download the zip file if it doesn't exist yet\n",
    "    if not os.path.exists(zip_filename):\n",
    "        url = f\"{base_url}{year}.zip\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(zip_filename, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded: {zip_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download data for year {year}. URL: {url}\")\n",
    "            continue\n",
    "\n",
    "    # extract the csv\n",
    "    if not os.path.exists(csv_filename):\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            csv_files = [name for name in zip_ref.namelist() if name.endswith(f\"CRASH_PHILADELPHIA_{year}.csv\")]\n",
    "            if csv_files:\n",
    "                zip_ref.extract(csv_files[0], download_dir)\n",
    "                print(f\"Extracted: {csv_filename}\")\n",
    "            else:\n",
    "                print(f\"Relevant CSV file not found in {zip_filename}\")\n",
    "                continue\n",
    "\n",
    "    # load csv as df\n",
    "    if os.path.exists(csv_filename):\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        df['year'] = year\n",
    "        crash_data_list.append(df)\n",
    "\n",
    "# combine all years into a single df\n",
    "if crash_data_list:\n",
    "    all_crashes = pd.concat(crash_data_list, ignore_index=True)\n",
    "    print(\"Combined all years into a single DataFrame.\")\n",
    "else:\n",
    "    print(\"No data loaded.\")\n",
    "\n",
    "# delete the zip and csv files\n",
    "for year in range(2018, 2024):\n",
    "    zip_filename = f\"{download_dir}/Philadelphia_{year}.zip\"\n",
    "    csv_filename = f\"{download_dir}/CRASH_PHILADELPHIA_{year}.csv\"\n",
    "    \n",
    "    if os.path.exists(zip_filename):\n",
    "        os.remove(zip_filename)\n",
    "        print(f\"Deleted: {zip_filename}\")\n",
    "    \n",
    "    if os.path.exists(csv_filename):\n",
    "        os.remove(csv_filename)\n",
    "        print(f\"Deleted: {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select for non-motorist crashes only\n",
    "non_motorist_crashes = all_crashes[all_crashes['NONMOTR_COUNT'] > 0]\n",
    "\n",
    "# filter out records with missing geography\n",
    "non_motorist_crashes = non_motorist_crashes.dropna(subset=['DEC_LAT', 'DEC_LONG'])\n",
    "\n",
    "# convert to gdf using lat and long\n",
    "geometry = gpd.points_from_xy(non_motorist_crashes['DEC_LONG'], non_motorist_crashes['DEC_LAT'])\n",
    "non_motorist_gdf = gpd.GeoDataFrame(non_motorist_crashes, geometry=geometry, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ade9c",
   "metadata": {},
   "source": [
    "## Visualizing the crash data\n",
    "\n",
    "### Crash point data by year\n",
    "\n",
    "Now that we have imported and prepared the crash data, we will quickly visualize them in the following interactive map.\n",
    "\n",
    "Years can be toggled on and off to see distributions of crashes across time. Reducing the number of years visualized as well as zooming into the map reduces the relative size of the dots, making it easier to see the spatial distribution of crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9b4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base map centered on Philadelphia\n",
    "m = folium.Map(location=[39.9526, -75.1652], zoom_start=12, tiles=\"cartodb positron\")\n",
    "\n",
    "# group crashes by year\n",
    "year_groups = non_motorist_gdf.groupby('year')\n",
    "\n",
    "# create a feature group for each year\n",
    "year_layers = {}\n",
    "\n",
    "for year, group in year_groups:\n",
    "    year_data = group.copy()\n",
    "    \n",
    "    # create geometries from lat and long\n",
    "    year_data['geometry'] = gpd.GeoSeries.from_xy(year_data['DEC_LONG'], year_data['DEC_LAT'])\n",
    "    year_gdf = gpd.GeoDataFrame(year_data, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    \n",
    "    # create a feature group for year\n",
    "    year_layer = folium.FeatureGroup(name=str(year))\n",
    "    \n",
    "    for _, row in year_gdf.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['DEC_LAT'], row['DEC_LONG']],\n",
    "            radius=5,\n",
    "            popup=f\"Crash ID: {row['CRN']}<br>Year: {row['year']}\",\n",
    "            color='blue',\n",
    "            fill=True,\n",
    "            fill_color='blue',\n",
    "            fill_opacity=0.6\n",
    "        ).add_to(year_layer)\n",
    "    \n",
    "    # add year layer to dictionary\n",
    "    year_layers[year] = year_layer\n",
    "\n",
    "# add all layers to map\n",
    "for year, layer in year_layers.items():\n",
    "    layer.add_to(m)\n",
    "\n",
    "# add layer control to toggle years with checkboxes\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# display map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e03b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save non motorist crashes as a geojson file for next notebook\n",
    "non_motorist_gdf.to_file(\"non_motorist_gdf.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-550-fall-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
